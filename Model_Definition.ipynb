{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c2f112",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Kiểm tra setup\n",
    "try:\n",
    "    from shared_variables import *\n",
    "except:\n",
    "    # Tải các biến và hàm từ notebook trước\n",
    "    %run \"1_Setup_and_Utils.ipynb\"\n",
    "    %run \"2_Image_Processing.ipynb\"\n",
    "\n",
    "# Định nghĩa lớp SignLanguageModel\n",
    "class SignLanguageModel:\n",
    "    def __init__(self, model_path=None):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n",
    "                       'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', \n",
    "                       'space', 'delete', 'nothing']\n",
    "        \n",
    "        if self.model_path:\n",
    "            self.load_model()\n",
    "        else:\n",
    "            self._create_model()\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create a CNN model for sign language recognition\"\"\"\n",
    "        model = tf.keras.Sequential([\n",
    "            # Lớp Conv2D đầu tiên\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Lớp Conv2D thứ hai\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Lớp Conv2D thứ ba\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            \n",
    "            # Flatten và các lớp fully connected\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(len(self.labels), activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        self.model = model\n",
    "        print(\"Created a new model. Note: This model is untrained.\")\n",
    "\n",
    "    def load_model(self):\n",
    "        try:\n",
    "            self.model = tf.keras.models.load_model(self.model_path)\n",
    "            print(f\"Model loaded successfully from {self.model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Creating a new model instead...\")\n",
    "            self._create_model()\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Preprocess the input image for prediction\"\"\"\n",
    "        # Lấy hàm resize_image từ shared variables\n",
    "        resize_image = load_variable('resize_image')\n",
    "        if resize_image is None:\n",
    "            # Fallback nếu không tìm thấy hàm\n",
    "            from 2_Image_Processing import resize_image\n",
    "        \n",
    "        # Convert OpenCV image to PIL Image\n",
    "        if len(image.shape) == 3:  # Color image\n",
    "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        else:  # Already grayscale\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        # Resize image\n",
    "        image = resize_image(image, (64, 64), preserve_aspect_ratio=True)\n",
    "        \n",
    "        # Convert to grayscale if needed\n",
    "        if isinstance(image, Image.Image):\n",
    "            if image.mode != 'L':\n",
    "                image = image.convert('L')\n",
    "            img_array = np.array(image)\n",
    "        else:\n",
    "            if len(image.shape) == 3:\n",
    "                img_array = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            else:\n",
    "                img_array = image\n",
    "        \n",
    "        # Normalize and reshape\n",
    "        img_array = img_array.astype('float32') / 255.0\n",
    "        img_array = img_array.reshape(1, 64, 64, 1)\n",
    "        \n",
    "        return img_array\n",
    "\n",
    "    def predict_sign(self, image):\n",
    "        \"\"\"Predict the sign from an image\"\"\"\n",
    "        # Ensure image is grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray_image = image\n",
    "            \n",
    "        # Check if the image has enough variation to be a hand\n",
    "        std_dev = np.std(gray_image)\n",
    "        if std_dev < 20:  # If low variation, likely no hand\n",
    "            return \"?\", 0.0\n",
    "\n",
    "        # Process image\n",
    "        processed_image = self.preprocess_image(gray_image)\n",
    "        \n",
    "        # Make prediction\n",
    "        predictions = self.model.predict(processed_image, verbose=0)\n",
    "        \n",
    "        # Get the index of the highest confidence prediction\n",
    "        predicted_index = np.argmax(predictions[0])\n",
    "        confidence = predictions[0][predicted_index]\n",
    "        \n",
    "        # Map the index to the sign\n",
    "        if predicted_index < 26:  # A-Z\n",
    "            predicted_sign = chr(65 + predicted_index)\n",
    "        else:\n",
    "            special_classes = {26: \"space\", 27: \"delete\", 28: \"nothing\"}\n",
    "            predicted_sign = special_classes.get(predicted_index, \"?\")\n",
    "        \n",
    "        return predicted_sign, confidence\n",
    "\n",
    "# Lưu model class để chia sẻ\n",
    "save_variable(SignLanguageModel, 'SignLanguageModel')\n",
    "\n",
    "# Hiển thị kiến trúc mô hình để kiểm tra\n",
    "model = SignLanguageModel()\n",
    "model.model.summary()\n",
    "\n",
    "# Tùy chọn lưu model để chia sẻ\n",
    "save_variable(model, 'model_instance')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
