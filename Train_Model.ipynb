{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93b55e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Kiểm tra setup\n",
    "try:\n",
    "    from shared_variables import *\n",
    "except:\n",
    "    # Tải các biến và hàm từ notebook trước\n",
    "    %run \"1_Setup_and_Utils.ipynb\"\n",
    "    %run \"3_Model_Definition.ipynb\"\n",
    "\n",
    "# Lấy SignLanguageModel class\n",
    "SignLanguageModel = load_variable('SignLanguageModel')\n",
    "\n",
    "# Hàm huấn luyện mô hình\n",
    "def train_model(data_dir, epochs=None, batch_size=None):\n",
    "    \"\"\"\n",
    "    Train the sign language model with automatic parameter tuning\n",
    "    \"\"\"\n",
    "    print(f\"Training model with data from {data_dir}\")\n",
    "    \n",
    "    # Ensure the data directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Directory {data_dir} does not exist\")\n",
    "        return None\n",
    "    \n",
    "    # Count samples and classes\n",
    "    total_images = 0\n",
    "    min_class_images = float('inf')\n",
    "    classes = []\n",
    "    \n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            classes.append(item)\n",
    "            img_count = len([f for f in os.listdir(item_path) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            total_images += img_count\n",
    "            min_class_images = min(min_class_images, img_count)\n",
    "            print(f\"  - Class {item}: {img_count} images\")\n",
    "    \n",
    "    print(f\"Total classes: {len(classes)}\")\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Minimum images per class: {min_class_images}\")\n",
    "    \n",
    "    if len(classes) == 0:\n",
    "        print(\"Error: No class directories found!\")\n",
    "        return None\n",
    "    \n",
    "    # Auto-calculate batch_size and epochs if not provided\n",
    "    if batch_size is None:\n",
    "        if min_class_images <= 8:\n",
    "            batch_size = 1\n",
    "        elif min_class_images <= 16:\n",
    "            batch_size = 4\n",
    "        elif min_class_images <= 32:\n",
    "            batch_size = 8\n",
    "        elif min_class_images <= 64:\n",
    "            batch_size = 16\n",
    "        else:\n",
    "            batch_size = 32\n",
    "        print(f\"Auto-selected batch_size = {batch_size}\")\n",
    "    \n",
    "    if epochs is None:\n",
    "        if total_images < 100:\n",
    "            epochs = 30\n",
    "        elif total_images < 500:\n",
    "            epochs = 20\n",
    "        elif total_images < 1000:\n",
    "            epochs = 15\n",
    "        else:\n",
    "            epochs = 10\n",
    "        print(f\"Auto-selected epochs = {epochs}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SignLanguageModel()\n",
    "    \n",
    "    # Load and prepare data\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=123,\n",
    "        image_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Normalize data\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    validation_ds = validation_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "    \n",
    "    # Data augmentation - adjust strength based on dataset size\n",
    "    augmentation_strength = 0.2 if total_images > 1000 else (0.3 if total_images > 500 else 0.4)\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomRotation(augmentation_strength),\n",
    "        tf.keras.layers.RandomTranslation(augmentation_strength, augmentation_strength),\n",
    "        tf.keras.layers.RandomZoom(augmentation_strength),\n",
    "        tf.keras.layers.RandomContrast(augmentation_strength)\n",
    "    ])\n",
    "    \n",
    "    # Apply augmentation\n",
    "    train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
    "    \n",
    "    # Optimize performance\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_ds = validation_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping_patience = 5 if total_images < 500 else 3\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            patience=early_stopping_patience, \n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.2, \n",
    "            patience=2,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting model training...\")\n",
    "    history = model.model.fit(\n",
    "        train_ds,\n",
    "        validation_data=validation_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the model\n",
    "    model_file = \"models/sign_model.h5\"\n",
    "    model.model.save(model_file)\n",
    "    print(f\"Model saved to {model_file}\")\n",
    "    \n",
    "    # Lưu model để chia sẻ\n",
    "    save_variable(model, 'trained_model')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Lấy đường dẫn dataset từ notebook trước\n",
    "dataset_dir = load_variable('dataset_dir')\n",
    "if dataset_dir is None:\n",
    "    dataset_dir = \"dataset\"  # Default\n",
    "\n",
    "# Nhập tham số huấn luyện\n",
    "print(f\"Dataset directory: {dataset_dir}\")\n",
    "print(\"Enter epochs (press Enter for automatic):\")\n",
    "epochs_input = input()\n",
    "epochs = int(epochs_input) if epochs_input else None\n",
    "\n",
    "print(\"Enter batch size (press Enter for automatic):\")\n",
    "batch_size_input = input()\n",
    "batch_size = int(batch_size_input) if batch_size_input else None\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "trained_model = train_model(dataset_dir, epochs, batch_size)\n",
    "\n",
    "# Tùy chọn download mô hình\n",
    "print(\"Do you want to download the trained model? (y/n)\")\n",
    "download_choice = input().lower()\n",
    "if download_choice == 'y':\n",
    "    files.download(\"models/sign_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
