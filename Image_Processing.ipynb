{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ab976",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Kiểm tra setup\n",
    "try:\n",
    "    from shared_variables import *\n",
    "except:\n",
    "    # Tải các biến và hàm từ notebook 1\n",
    "    %run \"1_Setup_and_Utils.ipynb\"\n",
    "\n",
    "# Các hàm xử lý ảnh\n",
    "def resize_image(image, target_size, preserve_aspect_ratio=True):\n",
    "    \"\"\"\n",
    "    Resize an image to the target size with aspect ratio preserved\n",
    "    \"\"\"\n",
    "    target_w, target_h = target_size\n",
    "    \n",
    "    if isinstance(image, np.ndarray):\n",
    "        # OpenCV image\n",
    "        if preserve_aspect_ratio:\n",
    "            h0, w0 = image.shape[:2]\n",
    "            scale = min(target_w / w0, target_h / h0)\n",
    "            new_w, new_h = int(w0 * scale), int(h0 * scale)\n",
    "            \n",
    "            # Resize theo tỉ lệ\n",
    "            resized = cv2.resize(image, (new_w, new_h))\n",
    "            \n",
    "            # Tạo ảnh nền đen\n",
    "            if len(image.shape) == 3:\n",
    "                result = np.zeros((target_h, target_w, image.shape[2]), dtype=image.dtype)\n",
    "            else:\n",
    "                result = np.zeros((target_h, target_w), dtype=image.dtype)\n",
    "            \n",
    "            # Tính toán padding để căn giữa\n",
    "            pad_w = target_w - new_w\n",
    "            pad_h = target_h - new_h\n",
    "            pad_left = pad_w // 2\n",
    "            pad_top = pad_h // 2\n",
    "            \n",
    "            # Đặt ảnh resize vào giữa\n",
    "            if len(image.shape) == 3:\n",
    "                result[pad_top:pad_top+new_h, pad_left:pad_left+new_w, :] = resized\n",
    "            else:\n",
    "                result[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = resized\n",
    "                \n",
    "            return result\n",
    "        else:\n",
    "            return cv2.resize(image, target_size)\n",
    "    else:\n",
    "        # PIL Image\n",
    "        if preserve_aspect_ratio:\n",
    "            w0, h0 = image.size\n",
    "            scale = min(target_w / w0, target_h / h0)\n",
    "            new_w, new_h = int(w0 * scale), int(h0 * scale)\n",
    "            \n",
    "            resized = image.resize((new_w, new_h), Image.LANCZOS)\n",
    "            \n",
    "            if image.mode == \"L\":\n",
    "                result = Image.new(\"L\", (target_w, target_h), 0)\n",
    "            else:\n",
    "                result = Image.new(\"RGB\", (target_w, target_h), (0, 0, 0))\n",
    "                \n",
    "            x_offset = (target_w - new_w) // 2\n",
    "            y_offset = (target_h - new_h) // 2\n",
    "            \n",
    "            result.paste(resized, (x_offset, y_offset))\n",
    "            return result\n",
    "        else:\n",
    "            return image.resize(target_size, Image.LANCZOS)\n",
    "\n",
    "def convert_to_grayscale(image):\n",
    "    \"\"\"\n",
    "    Convert an image to grayscale\n",
    "    \"\"\"\n",
    "    if isinstance(image, np.ndarray):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        return image.convert(\"L\")\n",
    "\n",
    "def extract_hand_region(image, roi_size=300):\n",
    "    \"\"\"\n",
    "    Extract the hand region from the image using skin color detection\n",
    "    \"\"\"\n",
    "    # Define region of interest (ROI) in the center-right of the frame\n",
    "    height, width = image.shape[:2]\n",
    "    roi_x = width // 2 - roi_size // 2\n",
    "    roi_y = height // 2 - roi_size // 2\n",
    "    \n",
    "    # Ensure ROI is within image bounds\n",
    "    roi_x = max(0, min(roi_x, width - roi_size))\n",
    "    roi_y = max(0, min(roi_y, height - roi_size))\n",
    "    \n",
    "    # Extract ROI\n",
    "    roi = image[roi_y:roi_y+roi_size, roi_x:roi_x+roi_size].copy()\n",
    "    \n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define range for skin color detection\n",
    "    lower_skin = np.array([0, 20, 70], dtype=np.uint8)\n",
    "    upper_skin = np.array([20, 255, 255], dtype=np.uint8)\n",
    "    \n",
    "    # Create binary mask for skin color\n",
    "    mask = cv2.inRange(hsv, lower_skin, upper_skin)\n",
    "    \n",
    "    # Apply morphological operations to improve the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw ROI boundary for visual guidance\n",
    "    cv2.rectangle(image, (roi_x, roi_y), (roi_x + roi_size, roi_y + roi_size), \n",
    "                 (255, 0, 0), 2)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the largest contour (assume it's the hand)\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        contour_area = cv2.contourArea(max_contour)\n",
    "        \n",
    "        # If the contour is large enough (avoid small noise)\n",
    "        if contour_area > 3000:\n",
    "            # Get bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(max_contour)\n",
    "            \n",
    "            # Add some padding\n",
    "            padding = 20\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            w = min(roi_size - x, w + 2*padding)\n",
    "            h = min(roi_size - y, h + 2*padding)\n",
    "            \n",
    "            # Extract the hand region from the ROI\n",
    "            hand = roi[y:y+h, x:x+w]\n",
    "            \n",
    "            # Draw the rectangle on original image for visualization\n",
    "            cv2.rectangle(image, (roi_x + x, roi_y + y), \n",
    "                         (roi_x + x + w, roi_y + y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display contour area for debugging\n",
    "            cv2.putText(image, f\"Area: {contour_area:.0f}\", (roi_x, roi_y - 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            if hand.size > 0:\n",
    "                # Thêm text khi phát hiện tay\n",
    "                cv2.putText(image, \"Hand Detected\", (roi_x, roi_y - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                return hand\n",
    "    \n",
    "    # If no good hand region is detected\n",
    "    cv2.putText(image, \"No hand detected\", (roi_x, roi_y - 10),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "               \n",
    "    # Return a blurred version of ROI instead of the original one\n",
    "    blurred_roi = cv2.GaussianBlur(roi, (25, 25), 0)\n",
    "    return blurred_roi\n",
    "\n",
    "def draw_prediction(image, sign, confidence):\n",
    "    \"\"\"\n",
    "    Draw prediction text on the image\n",
    "    \"\"\"\n",
    "    # Create a copy of the image\n",
    "    result = image.copy()\n",
    "    \n",
    "    # Draw a semi-transparent rectangle for text background\n",
    "    overlay = result.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (300, 140), (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay, 0.6, result, 0.4, 0, result)\n",
    "    \n",
    "    # Define text to display\n",
    "    if sign == \"?\" or confidence < 0.5:\n",
    "        text = \"Waiting for hand gesture...\"\n",
    "        color = (0, 0, 255)  # Red\n",
    "    else:\n",
    "        text = f\"Sign: {sign} ({confidence:.2f})\"\n",
    "        color = (0, 255, 0)  # Green\n",
    "    \n",
    "    # Draw the text\n",
    "    cv2.putText(result, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "    # Draw hand placement guide\n",
    "    height, width = image.shape[:2]\n",
    "    roi_size = 300\n",
    "    roi_x = width // 2 - roi_size // 2\n",
    "    roi_y = height // 2 - roi_size // 2\n",
    "    cv2.rectangle(result, (roi_x, roi_y), (roi_x + roi_size, roi_y + roi_size), \n",
    "                 (255, 0, 0), 2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Lưu các hàm xử lý ảnh để chia sẻ với các notebook khác\n",
    "save_variable(resize_image, 'resize_image')\n",
    "save_variable(convert_to_grayscale, 'convert_to_grayscale')\n",
    "save_variable(extract_hand_region, 'extract_hand_region')\n",
    "save_variable(draw_prediction, 'draw_prediction')\n",
    "\n",
    "# Test các hàm với ảnh mẫu (tùy chọn)\n",
    "print(\"Bạn có muốn thử nghiệm các hàm xử lý ảnh với một ảnh mẫu? (y/n)\")\n",
    "test_image = input()\n",
    "if test_image.lower() == 'y':\n",
    "    print(\"Vui lòng upload một ảnh để thử nghiệm:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        for filename, content in uploaded.items():\n",
    "            image = cv2.imdecode(np.frombuffer(content, np.uint8), cv2.IMREAD_COLOR)\n",
    "            \n",
    "            print(\"Ảnh gốc:\")\n",
    "            display_image(image)\n",
    "            \n",
    "            print(\"Ảnh được resize về 64x64:\")\n",
    "            resized = resize_image(image, (64, 64))\n",
    "            display_image(resized)\n",
    "            \n",
    "            print(\"Ảnh grayscale:\")\n",
    "            gray = convert_to_grayscale(image)\n",
    "            display_image(gray)\n",
    "            \n",
    "            print(\"Phát hiện vùng tay:\")\n",
    "            hand_region = extract_hand_region(image.copy())\n",
    "            display_image(image)  # Show image with bounding box\n",
    "            display_image(hand_region)  # Show extracted hand region"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
