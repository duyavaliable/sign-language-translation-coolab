# -*- coding: utf-8 -*-
"""
Sign Language Translation - Optimized for Local Environment
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO

# ==================== C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_DIR = os.path.join(BASE_DIR, 'dataset')
MODELS_DIR = os.path.join(BASE_DIR, 'models')
TRAIN_DIR = os.path.join(BASE_DIR, 'train')

# ==================== KH·ªûI T·∫†O MODEL ====================
print("üîÑ ƒêang t·∫£i YOLO model...")
yolo_model = None  # S·∫Ω load khi c·∫ßn thi·∫øt

def get_yolo_model(model_path='yolov5su.pt'):
    """Lazy loading YOLO model"""
    global yolo_model
    if yolo_model is None:
        yolo_model = YOLO(model_path)
        print(f"‚úì ƒê√£ t·∫£i model: {model_path}")
    return yolo_model

# ==================== CH·ª®C NƒÇNG X·ª¨ L√ù ·∫¢NH ====================
def extract_hand_region(image, model_path='yolov5su.pt'):
    """
    Tr√≠ch xu·∫•t v√πng tay t·ª´ ·∫£nh s·ª≠ d·ª•ng YOLO detection
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o (numpy array)
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn YOLO model
    
    Returns:
        hand_box: V√πng ·∫£nh ch·ª©a b√†n tay ho·∫∑c ·∫£nh tr·ªëng n·∫øu kh√¥ng ph√°t hi·ªán
    """
    model = get_yolo_model(model_path)
    results = model(image)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    
    if len(boxes) > 0:
        # Ch·ªçn box l·ªõn nh·∫•t (gi·∫£ s·ª≠ l√† tay)
        areas = [(x2-x1)*(y2-y1) for x1, y1, x2, y2 in boxes]
        idx = areas.index(max(areas))
        x1, y1, x2, y2 = boxes[idx].astype(int)
        hand_box = image[y1:y2, x1:x2]
        
        # V·∫Ω bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, "Hand Detected (YOLO)", (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        return hand_box
    
    # Kh√¥ng ph√°t hi·ªán tay
    cv2.putText(image, "No hand detected", (20, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    return np.zeros((64, 64, 3), dtype=np.uint8)

def draw_prediction(image, sign, confidence):
    """
    V·∫Ω k·∫øt qu·∫£ d·ª± ƒëo√°n l√™n ·∫£nh
    
    Args:
        image: ·∫¢nh g·ªëc
        sign: K√Ω hi·ªáu ƒë∆∞·ª£c d·ª± ƒëo√°n
        confidence: ƒê·ªô tin c·∫≠y
    
    Returns:
        result: ·∫¢nh ƒë√£ v·∫Ω k·∫øt qu·∫£
    """
    result = image.copy()
    
    # V·∫Ω n·ªÅn cho text
    overlay = result.copy()
    cv2.rectangle(overlay, (10, 10), (300, 140), (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.6, result, 0.4, 0, result)
    
    # X√°c ƒë·ªãnh text v√† m√†u
    if sign == "?" or confidence < 0.5:
        text = "Waiting for hand gesture..."
        color = (0, 0, 255)  # Red
    else:
        text = f"Sign: {sign} ({confidence:.2f})"
        color = (0, 255, 0)  # Green
    
    cv2.putText(result, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    
    # V·∫Ω khung h∆∞·ªõng d·∫´n ƒë·∫∑t tay
    height, width = image.shape[:2]
    roi_size = 300
    roi_x = width // 2 - roi_size // 2
    roi_y = height // 2 - roi_size // 2
    cv2.rectangle(result, (roi_x, roi_y), (roi_x + roi_size, roi_y + roi_size),
                 (255, 0, 0), 2)
    
    return result

# ==================== HI·ªÇN TH·ªä DATASET ====================
def visualize_dataset(data_dir=None, num_samples=3):
    """
    Hi·ªÉn th·ªã m·∫´u t·ª´ dataset
    
    Args:
        data_dir: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c dataset
        num_samples: S·ªë l∆∞·ª£ng m·∫´u hi·ªÉn th·ªã cho m·ªói class
    """
    if data_dir is None:
        data_dir = os.path.join(DATASET_DIR, 'train', 'images')
    
    if not os.path.exists(data_dir):
        print(f"‚ùå Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i.")
        return
    
    # L·∫•y danh s√°ch c√°c class folders
    classes = sorted([d for d in os.listdir(data_dir)
                    if os.path.isdir(os.path.join(data_dir, d))])
    
    if not classes:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y class n√†o trong {data_dir}")
        return
    
    num_classes = len(classes)
    fig = plt.figure(figsize=(12, 2*num_classes))
    
    for i, class_name in enumerate(classes):
        class_dir = os.path.join(data_dir, class_name)
        images = [f for f in os.listdir(class_dir)
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if not images:
            continue
        
        samples = images[:num_samples] if len(images) > num_samples else images
        
        for j, image_name in enumerate(samples):
            idx = i * num_samples + j + 1
            ax = fig.add_subplot(num_classes, num_samples, idx)
            
            image_path = os.path.join(class_dir, image_name)
            img = cv2.imread(image_path)
            
            if img is not None:
                if len(img.shape) == 3:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                
                ax.imshow(img, cmap='gray' if len(img.shape) == 2 else None)
                ax.set_title(f"{class_name}")
                ax.axis('off')
    
    plt.tight_layout()
    plt.show()

# ==================== T·∫†O FILE C·∫§U H√åNH ====================
def create_dataset_yaml(use_all: bool = False):
    """
    T·∫°o file dataset.yaml cho YOLO training
    If use_all True -> val points to train/images (use all data for training + val)
    """
    os.makedirs(TRAIN_DIR, exist_ok=True)
    
    dataset_yaml_path = os.path.join(TRAIN_DIR, 'dataset.yaml')
    val_path = 'train/images' if use_all else 'val/images'
    
    dataset_yaml_content = f"""\
path: {DATASET_DIR}
train: train/images
val: {val_path}

nc: 22
names:
  - A
  - B
  - C
  - D
  - E
  - G
  - H
  - I
  - K
  - L
  - M
  - N
  - O
  - P
  - Q
  - R
  - S
  - T
  - U
  - V
  - X
  - Y
"""
    
    with open(dataset_yaml_path, "w", encoding='utf-8') as f:
        f.write(dataset_yaml_content)
    print(f"‚úì ƒê√£ t·∫°o dataset.yaml t·∫°i: {dataset_yaml_path} (use_all={use_all})")
    
    return dataset_yaml_path

# ==================== TRAINING ====================
def train_model(epochs=50, batch=16, imgsz=640, model_name='yolov5n.pt', use_all: bool = False):
    """
    Hu·∫•n luy·ªán YOLO model
    
    Args:
        epochs: S·ªë epoch training
        batch: Batch size
        imgsz: K√≠ch th∆∞·ªõc ·∫£nh
        model_name: T√™n pretrained model
    
    Returns:
        model: Model ƒë√£ ƒë∆∞·ª£c train
        results: K·∫øt qu·∫£ training
    """
    print("üöÄ B·∫Øt ƒë·∫ßu training...")
    
    # T·∫°o dataset.yaml
    dataset_yaml_path = create_dataset_yaml(use_all=use_all)
    
    # Ki·ªÉm tra dataset.yaml
    if not os.path.exists(dataset_yaml_path):
        raise FileNotFoundError(f"‚ùå dataset.yaml kh√¥ng t√¨m th·∫•y: {dataset_yaml_path}")
    
    # Load model
    model = YOLO(model_name)
    print(f"‚úì ƒê√£ load pretrained model: {model_name}")
    
    # Ki·ªÉm tra dataset structure
    train_images = os.path.join(DATASET_DIR, 'train', 'images')
    train_labels = os.path.join(DATASET_DIR, 'train', 'labels')
    val_images = os.path.join(DATASET_DIR, 'val', 'images')
    
    if not os.path.exists(train_images):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y: {train_images}")
    if not os.path.exists(train_labels):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y: {train_labels}")
    
    # Train
    print(f"üìä Training v·ªõi {epochs} epochs, batch={batch}, imgsz={imgsz}")
    results = model.train(
        data=dataset_yaml_path,
        epochs=epochs,
        imgsz=imgsz,
        batch=batch,
        project=MODELS_DIR,
        name='sign_language_model'
    )
    
    print("‚úÖ Training ho√†n t·∫•t!")
    return model, results

# ==================== D·ª∞ ƒêO√ÅN ====================
def predict_image(model, image_path, save_result=True):
    """
    D·ª± ƒëo√°n tr√™n m·ªôt ·∫£nh
    
    Args:
        model: YOLO model ƒë√£ train
        image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
        save_result: L∆∞u k·∫øt qu·∫£ hay kh√¥ng
    
    Returns:
        image_with_prediction: ·∫¢nh v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n
    """
    image = cv2.imread(image_path)
    
    if image is None:
        print(f"‚ùå L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·ª´ {image_path}")
        return None
    
    # D·ª± ƒëo√°n
    results = model(image)
    detections = results[0].boxes
    
    image_with_prediction = image.copy()
    
    if len(detections) > 0:
        for box in detections:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
            confidence = box.conf[0].cpu().numpy()
            class_id = int(box.cls[0].cpu().numpy())
            predicted_sign = model.names[class_id] if hasattr(model, 'names') else f"Class {class_id}"
            
            # V·∫Ω bounding box
            color = (0, 255, 0)
            cv2.rectangle(image_with_prediction, (x1, y1), (x2, y2), color, 2)
            
            # V·∫Ω text
            text = f"{predicted_sign}: {confidence:.2f}"
            cv2.putText(image_with_prediction, text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        print(f"‚úì Ph√°t hi·ªán {len(detections)} ƒë·ªëi t∆∞·ª£ng")
    else:
        print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng n√†o")
        cv2.putText(image_with_prediction, "No objects detected", (20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    cv2.imshow("Prediction Result", image_with_prediction)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    # L∆∞u k·∫øt qu·∫£
    if save_result:
        output_path = os.path.join(MODELS_DIR, 'prediction_result.jpg')
        cv2.imwrite(output_path, image_with_prediction)
        print(f"‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ t·∫°i: {output_path}")
    
    return image_with_prediction

# ==================== MAIN ====================
if __name__ == "__main__":
    print("=" * 60)
    print("ü§ñ SIGN LANGUAGE TRANSLATION - LOCAL VERSION")
    print("=" * 60)
    print(f"üìÅ Base Directory: {BASE_DIR}")
    print(f"üìÅ Dataset Directory: {DATASET_DIR}")
    print(f"üìÅ Models Directory: {MODELS_DIR}")
    print("=" * 60)
    
    # Menu l·ª±a ch·ªçn
    print("\nCh·ªçn ch·ª©c nƒÉng:")
    print("1. T·∫°o file dataset.yaml")
    print("2. Visualize dataset")
    print("3. Train model")
    print("4. Predict tr√™n ·∫£nh")
    print("0. Tho√°t")
    
    choice = input("\nNh·∫≠p l·ª±a ch·ªçn c·ªßa b·∫°n: ")
    
    if choice == "1":
        create_dataset_yaml()
    
    elif choice == "2":
        visualize_dataset()
    
    elif choice == "3":
        epochs = int(input("Nh·∫≠p s·ªë epochs (m·∫∑c ƒë·ªãnh 50): ") or 50)
        batch = int(input("Nh·∫≠p batch size (m·∫∑c ƒë·ªãnh 16): ") or 16)
        model, results = train_model(epochs=epochs, batch=batch)
    
    elif choice == "4":
        model_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n model (ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng best.pt): ").strip()
        if not model_path:
            model_path = os.path.join(MODELS_DIR, 'sign_language_model', 'weights', 'best.pt')
        
        image_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: ").strip()
        
        if os.path.exists(model_path) and os.path.exists(image_path):
            model = YOLO(model_path)
            predict_image(model, image_path)
        else:
            print("‚ùå File kh√¥ng t·ªìn t·∫°i!")
    
    elif choice == "0":
        print("üëã T·∫°m bi·ªát!")
    
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")