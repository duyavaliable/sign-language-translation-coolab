# -*- coding: utf-8 -*-
"""
Sign Language Translation - YOLOv8 Detection
Optimized for Local Environment
"""

import os
import cv2
import numpy as np
import matplotlib
matplotlib.use('Agg')  # headless backend, kh√¥ng c·∫ßn Tcl/Tk
import matplotlib.pyplot as plt
from ultralytics import YOLO

# ==================== C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ====================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TRAIN_DIR = os.path.join(BASE_DIR, 'train')        # Th∆∞ m·ª•c train (images + labels)
VALID_DIR = os.path.join(BASE_DIR, 'valid')        # Th∆∞ m·ª•c validation
TEST_DIR = os.path.join(BASE_DIR, 'test')          # Th∆∞ m·ª•c test
MODELS_DIR = os.path.join(BASE_DIR, 'models')      # L∆∞u trained models
CONFIG_DIR = BASE_DIR                               # dataset.yaml s·∫Ω l∆∞u ·ªü root

# ==================== KH·ªûI T·∫†O MODEL ====================
print("üîÑ ƒêang kh·ªüi t·∫°o YOLO model...")
yolo_model = None  # S·∫Ω load khi c·∫ßn thi·∫øt
current_model_path = None  # Track model ƒëang d√πng

def get_yolo_model(model_path='yolov8n.pt'):
    """
    Lazy loading YOLO model v·ªõi kh·∫£ nƒÉng reload
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn YOLO model (m·∫∑c ƒë·ªãnh: yolov8n.pt - Detection)
    
    Returns:
        model: YOLO model instance
    """
    global yolo_model, current_model_path
    
    # Reload n·∫øu model_path kh√°c
    if yolo_model is None or current_model_path != model_path:
        if not os.path.exists(model_path):
            print(f"‚ö†Ô∏è Warning: Model '{model_path}' kh√¥ng t·ªìn t·∫°i.")
            print(f"   Ultralytics s·∫Ω t·ª± ƒë·ªông t·∫£i pretrained model t·ª´ internet.")
        
        yolo_model = YOLO(model_path)
        current_model_path = model_path
        print(f"‚úì ƒê√£ t·∫£i YOLOv8 Detection model: {model_path}")
    
    return yolo_model

# ==================== CH·ª®C NƒÇNG X·ª¨ L√ù ·∫¢NH ====================
def extract_hand_region(image, model_path='yolov8n.pt'):
    """
    Tr√≠ch xu·∫•t v√πng tay t·ª´ ·∫£nh s·ª≠ d·ª•ng YOLO detection
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o (numpy array)
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn YOLO detection model
    
    Returns:
        hand_box: V√πng ·∫£nh ch·ª©a b√†n tay ho·∫∑c ·∫£nh tr·ªëng n·∫øu kh√¥ng ph√°t hi·ªán
    """
    model = get_yolo_model(model_path)
    results = model(image, verbose=False)
    
    # L·∫•y boxes t·ª´ detection results
    if hasattr(results[0], 'boxes') and len(results[0].boxes) > 0:
        boxes = results[0].boxes.xyxy.cpu().numpy()
        
        # Ch·ªçn box l·ªõn nh·∫•t (gi·∫£ s·ª≠ l√† tay)
        areas = [(x2-x1)*(y2-y1) for x1, y1, x2, y2 in boxes]
        idx = areas.index(max(areas))
        x1, y1, x2, y2 = boxes[idx].astype(int)
        hand_box = image[y1:y2, x1:x2]
        
        # V·∫Ω bounding box
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, "Hand Detected (YOLOv8)", (x1, y1-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        return hand_box
    
    # Kh√¥ng ph√°t hi·ªán tay
    cv2.putText(image, "No hand detected", (20, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    return np.zeros((64, 64, 3), dtype=np.uint8)

def draw_prediction(image, sign, confidence):
    """
    V·∫Ω k·∫øt qu·∫£ d·ª± ƒëo√°n l√™n ·∫£nh
    
    Args:
        image: ·∫¢nh g·ªëc
        sign: K√Ω hi·ªáu ƒë∆∞·ª£c d·ª± ƒëo√°n
        confidence: ƒê·ªô tin c·∫≠y
    
    Returns:
        result: ·∫¢nh ƒë√£ v·∫Ω k·∫øt qu·∫£
    """
    result = image.copy()
    
    # V·∫Ω n·ªÅn cho text
    overlay = result.copy()
    cv2.rectangle(overlay, (10, 10), (300, 140), (0, 0, 0), -1)
    cv2.addWeighted(overlay, 0.6, result, 0.4, 0, result)
    
    # X√°c ƒë·ªãnh text v√† m√†u
    if sign == "?" or confidence < 0.5:
        text = "Waiting for hand gesture..."
        color = (0, 0, 255)  # Red
    else:
        text = f"Sign: {sign} ({confidence:.2f})"
        color = (0, 255, 0)  # Green
    
    cv2.putText(result, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    
    # V·∫Ω khung h∆∞·ªõng d·∫´n ƒë·∫∑t tay
    height, width = image.shape[:2]
    roi_size = 300
    roi_x = width // 2 - roi_size // 2
    roi_y = height // 2 - roi_size // 2
    cv2.rectangle(result, (roi_x, roi_y), (roi_x + roi_size, roi_y + roi_size),
                 (255, 0, 0), 2)
    
    return result

# ==================== HI·ªÇN TH·ªä DATASET ====================
def visualize_dataset(data_type='train', num_samples=3):
    """
    Hi·ªÉn th·ªã m·∫´u t·ª´ dataset
    
    Args:
        data_type: Lo·∫°i dataset ('train', 'valid', ho·∫∑c 'test')
        num_samples: S·ªë l∆∞·ª£ng m·∫´u hi·ªÉn th·ªã
    """
    # X√°c ƒë·ªãnh th∆∞ m·ª•c d·ª±a tr√™n data_type
    if data_type == 'train':
        data_dir = TRAIN_DIR
    elif data_type == 'valid':
        data_dir = VALID_DIR
    elif data_type == 'test':
        data_dir = TEST_DIR
    else:
        print(f"‚ùå data_type kh√¥ng h·ª£p l·ªá: {data_type}. Ch·ªçn 'train', 'valid', ho·∫∑c 'test'.")
        return
    
    images_dir = os.path.join(data_dir, 'images')
    labels_dir = os.path.join(data_dir, 'labels')
    
    if not os.path.exists(images_dir):
        print(f"‚ùå Th∆∞ m·ª•c {images_dir} kh√¥ng t·ªìn t·∫°i.")
        return
    
    # L·∫•y danh s√°ch ·∫£nh
    image_files = [f for f in os.listdir(images_dir) 
                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    if not image_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh trong {images_dir}")
        return
    
    print(f"üìÅ Dataset: {data_type.upper()}")
    print(f"üìÅ Images directory: {images_dir}")
    print(f"üìÅ Labels directory: {labels_dir}")
    print(f"üìä Total images: {len(image_files)}")
    
    # Ch·ªçn m·∫´u ng·∫´u nhi√™n
    import random
    samples = random.sample(image_files, min(num_samples, len(image_files)))
    
    # Hi·ªÉn th·ªã
    fig = plt.figure(figsize=(15, 5))
    
    for i, image_name in enumerate(samples):
        ax = fig.add_subplot(1, len(samples), i + 1)
        
        image_path = os.path.join(images_dir, image_name)
        img = cv2.imread(image_path)
        
        if img is not None:
            if len(img.shape) == 3:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            ax.imshow(img, cmap='gray' if len(img.shape) == 2 else None)
            ax.set_title(f"{image_name[:20]}...")
            ax.axis('off')
    
    plt.tight_layout()
    plt.show()
    print(f"‚úì Hi·ªÉn th·ªã {len(samples)} m·∫´u t·ª´ {data_type} dataset")

# ==================== T·∫†O FILE C·∫§U H√åNH ====================
def create_dataset_yaml():
    """
    T·∫°o file dataset.yaml cho YOLO Detection training
    
    Returns:
        dataset_yaml_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file yaml ƒë√£ t·∫°o
    """
    dataset_yaml_path = os.path.join(CONFIG_DIR, 'dataset.yaml')
    
    # Ki·ªÉm tra c√°c th∆∞ m·ª•c t·ªìn t·∫°i
    train_images = os.path.join(TRAIN_DIR, 'images')
    train_labels = os.path.join(TRAIN_DIR, 'labels')
    valid_images = os.path.join(VALID_DIR, 'images')
    valid_labels = os.path.join(VALID_DIR, 'labels')
    
    # C·∫£nh b√°o n·∫øu thi·∫øu th∆∞ m·ª•c
    if not os.path.exists(train_images):
        print(f"‚ö†Ô∏è  WARNING: {train_images} kh√¥ng t·ªìn t·∫°i!")
    if not os.path.exists(train_labels):
        print(f"‚ö†Ô∏è  WARNING: {train_labels} kh√¥ng t·ªìn t·∫°i!")
    if not os.path.exists(valid_images):
        print(f"‚ö†Ô∏è  WARNING: {valid_images} kh√¥ng t·ªìn t·∫°i!")
    if not os.path.exists(valid_labels):
        print(f"‚ö†Ô∏è  WARNING: {valid_labels} kh√¥ng t·ªìn t·∫°i!")
    
    dataset_yaml_content = f"""\
# YOLOv8 Detection Dataset Configuration
# Sign Language Translation - 22 ASL Letters

# ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn root directory
path: {BASE_DIR}

# ƒê∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi t·ª´ path
train: train/images
val: valid/images

# Number of classes
nc: 22

# Class names (ASL letters, excluding F and J)
names:
  - A
  - B
  - C
  - D
  - E
  - G
  - H
  - I
  - K
  - L
  - M
  - N
  - O
  - P
  - Q
  - R
  - S
  - T
  - U
  - V
  - X
  - Y
"""
    
    with open(dataset_yaml_path, "w", encoding='utf-8') as f:
        f.write(dataset_yaml_content)
    
    print(f"‚úì ƒê√£ t·∫°o dataset.yaml t·∫°i: {dataset_yaml_path}")
    print(f"  - Training path: train/images & train/labels")
    print(f"  - Validation path: valid/images & valid/labels")
    print(f"  - Task: Detection (bounding box)")
    
    return dataset_yaml_path

# ==================== TRAINING ====================
def train_model(epochs=50, batch=16, imgsz=640, model_name='yolov8n.pt'):
    """
    Hu·∫•n luy·ªán YOLO Detection model
    
    Args:
        epochs: S·ªë epochs training
        batch: Batch size
        imgsz: K√≠ch th∆∞·ªõc ·∫£nh input
        model_name: T√™n pretrained model 
                   - 'yolov8n.pt' (nano - nhanh)
                   - 'yolov8s.pt' (small)
                   - 'yolov8m.pt' (medium)
                   - 'yolov8l.pt' (large)
                   - 'yolov8x.pt' (xlarge - ch√≠nh x√°c nh·∫•t)
    
    Returns:
        model: YOLO model ƒë√£ train
        results: K·∫øt qu·∫£ training
    """
    print("=" * 60)
    print(f"üöÄ B·∫ÆT ƒê·∫¶U TRAINING YOLOv8 DETECTION MODEL")
    print("=" * 60)
    
    # T·∫°o dataset.yaml
    dataset_yaml_path = create_dataset_yaml()
    
    # Load pretrained model
    model = YOLO(model_name)
    print(f"\n‚úì ƒê√£ load pretrained model: {model_name}")
    print(f"  - Task: Detection (Bounding Box)")
    print(f"  - Architecture: YOLOv8")
    
    # Ki·ªÉm tra dataset structure
    train_images = os.path.join(TRAIN_DIR, 'images')
    train_labels = os.path.join(TRAIN_DIR, 'labels')
    valid_images = os.path.join(VALID_DIR, 'images')
    valid_labels = os.path.join(VALID_DIR, 'labels')
    
    if not os.path.exists(train_images):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y: {train_images}")
    if not os.path.exists(train_labels):
        raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y: {train_labels}")
    if not os.path.exists(valid_images):
        print(f"‚ö†Ô∏è  WARNING: {valid_images} kh√¥ng t·ªìn t·∫°i!")
        print("   Training s·∫Ω d√πng train data ƒë·ªÉ validation.")
    
    # ƒê·∫øm s·ªë ·∫£nh v√† labels
    num_train_images = len([f for f in os.listdir(train_images) 
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    num_train_labels = len([f for f in os.listdir(train_labels) 
                           if f.endswith('.txt')])
    
    num_valid_images = 0
    if os.path.exists(valid_images):
        num_valid_images = len([f for f in os.listdir(valid_images) 
                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    
    print(f"\nüìä Dataset Statistics:")
    print(f"  - Training images: {num_train_images}")
    print(f"  - Training labels: {num_train_labels}")
    print(f"  - Validation images: {num_valid_images}")
    print(f"  - Classes: 22 (ASL letters)")
    
    print(f"\n‚öôÔ∏è  Training Configuration:")
    print(f"  - Epochs: {epochs}")
    print(f"  - Batch size: {batch}")
    print(f"  - Image size: {imgsz}")
    print(f"  - Task: detect (bounding box)")
    
    # Train model
    print("\n" + "=" * 60)
    print("üèãÔ∏è  STARTING TRAINING...")
    print("=" * 60 + "\n")
    
    results = model.train(
        data=dataset_yaml_path,
        epochs=epochs,
        imgsz=imgsz,
        batch=batch,
        project=MODELS_DIR,
        name='sign_language_detection',
        task='detect',
        patience=10,  # Early stopping
        save=True,
        plots=True
    )
    
    print("\n" + "=" * 60)
    print("‚úÖ TRAINING HO√ÄN T·∫§T!")
    print("=" * 60)
    print(f"üìÅ Model ƒë∆∞·ª£c l∆∞u t·∫°i: {MODELS_DIR}/sign_language_detection/weights/best.pt")
    
    return model, results

# ==================== ƒê√ÅNH GI√Å MODEL ====================
def evaluate_model(model_path, data_type='test'):
    """
    ƒê√°nh gi√° model tr√™n test dataset
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn trained model
        data_type: Lo·∫°i dataset ƒë·ªÉ ƒë√°nh gi√° ('test' ho·∫∑c 'val')
    
    Returns:
        metrics: K·∫øt qu·∫£ ƒë√°nh gi√°
    """
    print("=" * 60)
    print(f"üìä ƒê√ÅNH GI√Å MODEL TR√äN {data_type.upper()} DATASET")
    print("=" * 60)
    
    if not os.path.exists(model_path):
        print(f"‚ùå Model kh√¥ng t·ªìn t·∫°i: {model_path}")
        return None
    
    # Load model
    model = YOLO(model_path)
    print(f"‚úì ƒê√£ load model: {model_path}")
    
    # T·∫°o dataset.yaml n·∫øu ch∆∞a c√≥
    dataset_yaml_path = os.path.join(CONFIG_DIR, 'dataset.yaml')
    if not os.path.exists(dataset_yaml_path):
        print("‚ö†Ô∏è  dataset.yaml ch∆∞a t·ªìn t·∫°i. ƒêang t·∫°o...")
        create_dataset_yaml()
    
    # Validate model
    print(f"\nüîç ƒêang ƒë√°nh gi√° tr√™n {data_type} dataset...\n")
    
    metrics = model.val(
        data=dataset_yaml_path,
        split=data_type,  # 'test' ho·∫∑c 'val'
        save_json=True,
        plots=True
    )
    
    print("\n" + "=" * 60)
    print("‚úÖ ƒê√ÅNH GI√Å HO√ÄN T·∫§T!")
    print("=" * 60)
    
    return metrics

# ==================== D·ª∞ ƒêO√ÅN ====================
def predict_image(model, image_path, save_result=True):
    """
    D·ª± ƒëo√°n tr√™n m·ªôt ·∫£nh v·ªõi YOLOv8 Detection
    
    Args:
        model: YOLO detection model ƒë√£ train
        image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
        save_result: L∆∞u k·∫øt qu·∫£ hay kh√¥ng
    
    Returns:
        image_with_prediction: ·∫¢nh v·ªõi k·∫øt qu·∫£ d·ª± ƒëo√°n
    """
    image = cv2.imread(image_path)
    
    if image is None:
        print(f"‚ùå L·ªói: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·ª´ {image_path}")
        return None
    
    # D·ª± ƒëo√°n
    results = model(image, verbose=False)
    
    # L·∫•y boxes
    boxes_arr = results[0].boxes.xyxy.cpu().numpy() if hasattr(results[0].boxes, 'xyxy') else np.array([])
    confs = results[0].boxes.conf.cpu().numpy() if hasattr(results[0].boxes, 'conf') else np.array([])
    cls_ids = results[0].boxes.cls.cpu().numpy().astype(int) if hasattr(results[0].boxes, 'cls') else np.array([])
    
    image_with_prediction = image.copy()
    
    if boxes_arr.size > 0:
        for i, box in enumerate(boxes_arr):
            x1, y1, x2, y2 = box.astype(int)
            confidence = float(confs[i]) if i < len(confs) else 0.0
            class_id = int(cls_ids[i]) if i < len(cls_ids) else -1
            predicted_sign = model.names[class_id] if (hasattr(model, 'names') and class_id in model.names) else f"Class {class_id}"
            
            # V·∫Ω bounding box
            color = (0, 255, 0)
            cv2.rectangle(image_with_prediction, (x1, y1), (x2, y2), color, 2)
            
            # V·∫Ω text
            text = f"{predicted_sign}: {confidence:.2f}"
            cv2.putText(image_with_prediction, text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        
        print(f"‚úì Ph√°t hi·ªán {len(boxes_arr)} ƒë·ªëi t∆∞·ª£ng")
    else:
        print("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng n√†o")
        cv2.putText(image_with_prediction, "No objects detected", (20, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ (v·ªõi error handling cho headless env)
    try:
        cv2.imshow("Prediction Result - YOLOv8 Detection", image_with_prediction)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    except Exception as e:
        print(f"‚ÑπÔ∏è  GUI kh√¥ng kh·∫£ d·ª•ng (headless environment): {e}")
        print("   K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o file thay v√¨ hi·ªÉn th·ªã.")
    
    # L∆∞u k·∫øt qu·∫£
    if save_result:
        os.makedirs(MODELS_DIR, exist_ok=True)
        output_path = os.path.join(MODELS_DIR, 'prediction_result.jpg')
        cv2.imwrite(output_path, image_with_prediction)
        print(f"‚úì ƒê√£ l∆∞u k·∫øt qu·∫£ t·∫°i: {output_path}")
    
    return image_with_prediction

# ==================== MAIN ====================
if __name__ == "__main__":
    print("=" * 60)
    print("ü§ñ SIGN LANGUAGE TRANSLATION - YOLOv8 DETECTION")
    print("=" * 60)
    print(f"üìÅ Base Directory: {BASE_DIR}")
    print(f"üìÅ Train Directory: {TRAIN_DIR}")
    print(f"üìÅ Valid Directory: {VALID_DIR}")
    print(f"üìÅ Test Directory: {TEST_DIR}")
    print(f"üìÅ Models Directory: {MODELS_DIR}")
    print(f"üîß Model: YOLOv8 Detection (yolov8n.pt)")
    print("=" * 60)
    
    # Menu l·ª±a ch·ªçn
    print("\nCh·ªçn ch·ª©c nƒÉng:")
    print("1. T·∫°o file dataset.yaml")
    print("2. Visualize dataset")
    print("3. Train model (YOLOv8 Detection)")
    print("4. Evaluate model (Test dataset)")
    print("5. Predict tr√™n ·∫£nh")
    print("0. Tho√°t")
    
    choice = input("\nNh·∫≠p l·ª±a ch·ªçn c·ªßa b·∫°n: ").strip()
    
    if choice == "1":
        create_dataset_yaml()
    
    elif choice == "2":
        print("\nCh·ªçn dataset:")
        print("1. Train")
        print("2. Valid")
        print("3. Test")
        data_choice = input("Nh·∫≠p l·ª±a ch·ªçn (m·∫∑c ƒë·ªãnh 1): ").strip() or "1"
        
        data_type_map = {"1": "train", "2": "valid", "3": "test"}
        data_type = data_type_map.get(data_choice, "train")
        
        visualize_dataset(data_type=data_type)
    
    elif choice == "3":
        print("\nCh·ªçn model size:")
        print("1. YOLOv8n (nano - nhanh nh·∫•t, √≠t ch√≠nh x√°c)")
        print("2. YOLOv8s (small - c√¢n b·∫±ng)")
        print("3. YOLOv8m (medium - ch√≠nh x√°c h∆°n)")
        model_choice = input("Nh·∫≠p l·ª±a ch·ªçn (m·∫∑c ƒë·ªãnh 1): ").strip() or "1"
        
        model_map = {
            "1": "yolov8n.pt",
            "2": "yolov8s.pt",
            "3": "yolov8m.pt"
        }
        model_name = model_map.get(model_choice, "yolov8n.pt")
        
        epochs = int(input("Nh·∫≠p s·ªë epochs (m·∫∑c ƒë·ªãnh 50): ").strip() or 50)
        batch = int(input("Nh·∫≠p batch size (m·∫∑c ƒë·ªãnh 16): ").strip() or 16)
        
        model, results = train_model(epochs=epochs, batch=batch, model_name=model_name)
    
    elif choice == "4":
        model_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n model (ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng best.pt): ").strip()
        if not model_path:
            model_path = os.path.join(MODELS_DIR, 'sign_language_detection', 'weights', 'best.pt')
        
        print("\nCh·ªçn dataset ƒë·ªÉ ƒë√°nh gi√°:")
        print("1. Test")
        print("2. Valid")
        eval_choice = input("Nh·∫≠p l·ª±a ch·ªçn (m·∫∑c ƒë·ªãnh 1): ").strip() or "1"
        
        data_type = "test" if eval_choice == "1" else "val"
        
        evaluate_model(model_path, data_type=data_type)
    
    elif choice == "5":
        model_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n model (ƒë·ªÉ tr·ªëng ƒë·ªÉ d√πng best.pt): ").strip()
        if not model_path:
            model_path = os.path.join(MODELS_DIR, 'sign_language_detection', 'weights', 'best.pt')
        
        image_path = input("Nh·∫≠p ƒë∆∞·ªùng d·∫´n ·∫£nh: ").strip()
        
        if os.path.exists(model_path) and os.path.exists(image_path):
            model = YOLO(model_path)
            predict_image(model, image_path)
        else:
            if not os.path.exists(model_path):
                print(f"‚ùå Model kh√¥ng t·ªìn t·∫°i: {model_path}")
            if not os.path.exists(image_path):
                print(f"‚ùå ·∫¢nh kh√¥ng t·ªìn t·∫°i: {image_path}")
    
    elif choice == "0":
        print("üëã T·∫°m bi·ªát!")
    
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")